DSII_HW1_co2554
================
Camille Okonkwo
2024-02-23

## loading training and testing data

``` r
testing_data = read_csv("data/housing_test.csv")
```

    ## Rows: 959 Columns: 26
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr  (4): Overall_Qual, Kitchen_Qual, Fireplace_Qu, Exter_Qual
    ## dbl (22): Gr_Liv_Area, First_Flr_SF, Second_Flr_SF, Total_Bsmt_SF, Low_Qual_...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
training_data = read_csv("data/housing_training.csv")
```

    ## Rows: 1440 Columns: 26
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr  (4): Overall_Qual, Kitchen_Qual, Fireplace_Qu, Exter_Qual
    ## dbl (22): Gr_Liv_Area, First_Flr_SF, Second_Flr_SF, Total_Bsmt_SF, Low_Qual_...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

1a) Fit a lasso model on the training data. Report the selected tuning
parameter and the test error. When the 1SE rule is applied, how many
predictors are included in the model?

## loading necessary packages

``` r
library(glmnet)
```

    ## Loading required package: Matrix

    ## 
    ## Attaching package: 'Matrix'

    ## The following objects are masked from 'package:tidyr':
    ## 
    ##     expand, pack, unpack

    ## Loaded glmnet 4.1-8

### specifying predictors and response variables

``` r
x <- model.matrix(Sale_Price ~ ., training_data)[,-1]
y <- as.numeric(training_data$Sale_Price)

library(corrplot)
```

    ## corrplot 0.92 loaded

``` r
corrplot(cor(x), method = "circle", type = "full")
```

![](HW1_co2554_files/figure-gfm/unnamed-chunk-3-1.png)<!-- -->

### fitting lasso model on the training data

``` r
set.seed(2)

cv.lasso <- cv.glmnet(x, y,
                      alpha = 1,
                      lambda = exp(seq(6, -5, length = 100)))

plot(cv.lasso)
```

![](HW1_co2554_files/figure-gfm/unnamed-chunk-4-1.png)<!-- -->

### selected tuning parameter and test error

``` r
# tuning parameter
cv.lasso$lambda.min
```

    ## [1] 48.85657

``` r
# test error
min(cv.lasso$cvm)
```

    ## [1] 534903510

The best tuning parameter selected for the lasso regression is an alpha
= 1 and a lambda = 48.857. The test error is 534903510.

### applying 1SE

``` r
# 1SE lambda
cv.lasso$lambda.1se
```

    ## [1] 403.4288

``` r
# extracting coefficients
lasso.1se <- predict(cv.lasso, s = cv.lasso$lambda.1se, type = "coefficients")

# counting how many predictors included in model
num_predictors_1se <- sum(lasso.1se != 0)
```

When the 1SE rule is applied, there are 37 predictors included in the
model.
